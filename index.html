<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice AI - Ghi √¢m & ƒê·ªçc</title>
    <style>
        /* ==== CSS ==== */
        body {
            font-family: Arial, sans-serif;
            background: #f0f2f5;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
            min-height: 100vh;
        }

        h1 {
            margin-top: 20px;
            color: #333;
        }

        .container {
            margin-top: 20px;
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0px 4px 10px rgba(0,0,0,0.1);
            width: 90%;
            max-width: 500px;
        }

        button {
            padding: 10px 20px;
            margin: 10px 5px;
            border: none;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            transition: 0.2s;
        }

        .record {
            background: #ff4d4f;
            color: white;
        }

        .record:hover {
            background: #d9363e;
        }

        .play {
            background: #4caf50;
            color: white;
        }

        .play:hover {
            background: #3e8e41;
        }

        textarea {
            width: 100%;
            height: 100px;
            margin-top: 10px;
            padding: 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
            resize: none;
        }
    </style>
</head>
<body>
    <h1>üéô Voice AI Demo</h1>
    <div class="container">
        <button class="record" id="recordBtn">üé§ B·∫Øt ƒë·∫ßu ghi √¢m</button>
        <textarea id="textOutput" placeholder="K·∫øt qu·∫£ vƒÉn b·∫£n..."></textarea>
        <button class="play" id="speakBtn">üîä ƒê·ªçc vƒÉn b·∫£n</button>
    </div>

    <script>
        /* ==== JS ==== */
        const API_KEY = "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";
        const recordBtn = document.getElementById("recordBtn");
        const speakBtn = document.getElementById("speakBtn");
        const textOutput = document.getElementById("textOutput");

        let mediaRecorder;
        let audioChunks = [];

        // üé§ Ghi √¢m gi·ªçng n√≥i
        recordBtn.addEventListener("click", async () => {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop();
                recordBtn.textContent = "üé§ B·∫Øt ƒë·∫ßu ghi √¢m";
                return;
            }
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];

            mediaRecorder.ondataavailable = e => {
                audioChunks.push(e.data);
            };

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                await sendToWhisper(audioBlob);
            };

            mediaRecorder.start();
            recordBtn.textContent = "‚èπ D·ª´ng ghi √¢m";
        });

        // üì§ G·ª≠i audio l√™n OpenAI Whisper API
        async function sendToWhisper(audioBlob) {
            const formData = new FormData();
            formData.append("file", audioBlob, "audio.webm");
            formData.append("model", "gpt-4o-mini-transcribe");

            const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
                method: "POST",
                headers: {
                    Authorization: `Bearer ${API_KEY}`
                },
                body: formData
            });

            const data = await response.json();
            textOutput.value = data.text || "L·ªói nh·∫≠n d·∫°ng gi·ªçng n√≥i!";
        }

        // üîä Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i
        speakBtn.addEventListener("click", async () => {
            const text = textOutput.value.trim();
            if (!text) return alert("Vui l√≤ng nh·∫≠p vƒÉn b·∫£n!");

            const response = await fetch("https://api.openai.com/v1/audio/speech", {
                method: "POST",
                headers: {
                    Authorization: `Bearer ${API_KEY}`,
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({
                    model: "gpt-4o-mini-tts",
                    voice: "alloy",
                    input: text
                })
            });

            const audioData = await response.arrayBuffer();
            const audioBlob = new Blob([audioData], { type: "audio/mpeg" });
            const audioUrl = URL.createObjectURL(audioBlob);
            new Audio(audioUrl).play();
        });
    </script>
</body>
</html>
